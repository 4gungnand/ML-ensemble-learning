{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFChoCfOPw7M"
      },
      "outputs": [],
      "source": [
        "# DataFrame\n",
        "import pandas as pd "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construct a tf.data.Dataset\n",
        "data = pd.read_csv(r\"marketing_campaign2.csv\",encoding='latin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check all the categorical columns from the dataset\n",
        "def count_unique_values(column_name):\n",
        "    value_counts = data[column_name].value_counts()\n",
        "    print(value_counts)\n",
        "\n",
        "# Call the function for different columns\n",
        "count_unique_values(\"Education\")\n",
        "print(\"\\n\")\n",
        "count_unique_values(\"Marital_Status\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert Categorical to Numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the date column to a numerical format\n",
        "#data[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"], format=\"%d-%m-%Y\").dt.strftime(\"%d%m%Y\").astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the mapping for Education\n",
        "education_mapping = {\n",
        "    'Graduation': 1,\n",
        "    'PhD': 2,\n",
        "    'Master': 3,\n",
        "    '2n Cycle': 4,\n",
        "    'Basic': 5\n",
        "}\n",
        "\n",
        "# Define the mapping for Marital_Status\n",
        "marital_status_mapping = {\n",
        "    'Married': 1,\n",
        "    'Together': 2,\n",
        "    'Single': 3,\n",
        "    'Divorced': 4,\n",
        "    'Widow': 5,\n",
        "    'Alone': 6,\n",
        "    'Absurd': 7,\n",
        "    'YOLO': 8,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Replace Education and Marital_Status with numerical values\n",
        "data['Education'] = data['Education'].replace(education_mapping)\n",
        "data['Marital_Status'] = data['Marital_Status'].replace(marital_status_mapping)\n",
        "\n",
        "# Print the updated dataframe\n",
        "data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Periksa apakah ada nilai yang hilang dalam dataset\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Tampilkan jumlah nilai yang hilang untuk setiap kolom\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hapus baris yang memiliki missing value pada kolom \"income\"\n",
        "data = data.dropna(subset=[\"Income\"])\n",
        "\n",
        "# Tampilkan dataset setelah menghapus baris dengan missing value pada kolom \"income\"\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Periksa apakah ada nilai yang hilang dalam dataset\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Tampilkan jumlah nilai yang hilang untuk setiap kolom\n",
        "print(missing_values)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customer_For"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mengubah kolom \"Dt_Customer\" menjadi tipe data datetime\n",
        "#data['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'])\n",
        "\n",
        "# Menghitung jumlah hari pelanggan terdaftar hingga tanggal terakhir dalam catatan\n",
        "#latest_date = data['Dt_Customer'].max()\n",
        "#data['Customer_For'] = (latest_date - data['Dt_Customer']).dt.days\n",
        "\n",
        "data['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'], format='%d-%m-%Y')\n",
        "latest_date = data['Dt_Customer'].max()\n",
        "data['Customer_For'] = (latest_date - data['Dt_Customer']).dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Customer_For']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Menghitung usia pelanggan berdasarkan tahun lahir (Year_Birth)\n",
        "current_year = datetime.datetime.now().year\n",
        "data['Age'] = current_year - data['Year_Birth']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Age']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Menjumlahkan total pengeluaran pelanggan dalam berbagai kategori selama rentang waktu dua tahun\n",
        "categories = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "data['Spent'] = data[categories].sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[['Spent', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Living_With"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the mapping for Marital_Status\n",
        "# marital_status_mapping = {\n",
        "#     'Married': 1,\n",
        "#     'Together': 2,\n",
        "#     'Single': 3,\n",
        "#     'Divorced': 4,\n",
        "#     'Widow': 5,\n",
        "#     'Alone': 6,\n",
        "#     'Absurd': 7,\n",
        "#     'YOLO': 8,\n",
        "# }\n",
        "\n",
        "# Mengatur nilai kolom \"Living_With\" berdasarkan kondisi marital status, teenhome, dan kidhome\n",
        "data.loc[data['Marital_Status'].isin([3, 4, 5, 6]), 'Living_With'] = 0 #'Alone'\n",
        "data.loc[data['Marital_Status'].isin([1, 2]), 'Living_With'] = 1 #'With_Partner'\n",
        "data.loc[data['Marital_Status'].isin([7, 8]), 'Living_With'] = 2 #'Absurd'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Children"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Menjumlahkan jumlah anak dalam sebuah rumah tangga\n",
        "data['Children'] = data['Kidhome'] + data['Teenhome']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Family_Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Menghitung jumlah orang dalam keluarga berdasarkan kondisi Living_With\n",
        "data.loc[data['Living_With'] == 0, 'Family_Size'] = data['Children']\n",
        "data.loc[data['Living_With'] == 1, 'Family_Size'] = data['Children'] + 1\n",
        "data.loc[data['Living_With'] == 2, 'Family_Size'] = data['Children']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Family_Size']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Is_Parent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mengecek apakah pelanggan merupakan orang tua atau bukan\n",
        "data['Is_Parent'] = data['Children'].apply(lambda x: '1' if x > 0 else '0')\n",
        "# Yes = 1, No = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Is_Parent to int\n",
        "data['Is_Parent'] = data['Is_Parent'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[['Children', 'Is_Parent']]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Education"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Education']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the mapping for Education\n",
        "# education_mapping = {\n",
        "#     'Graduation': 1,\n",
        "#     'PhD': 2,\n",
        "#     'Master': 3,\n",
        "#     '2n Cycle': 4,\n",
        "#     'Basic': 5\n",
        "# }\n",
        "\n",
        "# Mengatur nilai kolom \"Living_With\" berdasarkan kondisi marital status, teenhome, dan kidhome\n",
        "data.loc[data['Education'].isin([1]), 'Education_Category'] = 0 #'Bachelor'\n",
        "data.loc[data['Education'].isin([2, 3, 4]), 'Education_Category'] = 1 #'Advanced'\n",
        "data.loc[data['Education'].isin([5]), 'Education_Category'] = 2 #'High School'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Education_Category']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Menghapus fitur-fitur yang redundan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "redundant_features = ['ID', 'Year_Birth', 'Dt_Customer', 'Education', 'Marital_Status', 'Kidhome', 'Teenhome','MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "data = data.drop(redundant_features, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Library\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_columns = [\"Income\", \"Recency\", \"Customer_For\", \"Age\", \"Spent\", \"Is_Parent\"]\n",
        "\n",
        "for column in selected_columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=data, y=column)\n",
        "    plt.title(f\"Box Plot of {column}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Calculate z-scores for the specified columns\n",
        "z_scores_income = stats.zscore(data['Income'])\n",
        "z_scores_age = stats.zscore(data['Age'])\n",
        "z_scores_spent = stats.zscore(data['Spent'])\n",
        "\n",
        "print(z_scores_income)\n",
        "\n",
        "# Set threshold range for z-scores (e.g., within 3 standard deviations)\n",
        "threshold = 3\n",
        "filtered_data = data[\n",
        "    (z_scores_income > -threshold) & (z_scores_income < threshold) &\n",
        "    (z_scores_age > -threshold) & (z_scores_age < threshold) &\n",
        "    (z_scores_spent > -threshold) & (z_scores_spent < threshold)\n",
        "]\n",
        "\n",
        "# Check the number of outliers removed for each column\n",
        "outliers_removed_income = len(data) - len(filtered_data)\n",
        "outliers_removed_age = len(data) - len(filtered_data)\n",
        "outliers_removed_spent = len(data) - len(filtered_data)\n",
        "print(f\"Number of outliers removed from 'Income': {outliers_removed_income}\")\n",
        "print(f\"Number of outliers removed from 'Age': {outliers_removed_age}\")\n",
        "print(f\"Number of outliers removed from 'Spent': {outliers_removed_spent}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lihat kembali boxplot pada kolom yang di proses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_columns = [\"Income\", \"Age\", \"Spent\"]\n",
        "\n",
        "for column in selected_columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=filtered_data, y=column)\n",
        "    plt.title(f\"Box Plot of {column} (Outliers Removed)\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "columns = ['Income', 'Recency', 'Customer_For', 'Age', 'Spent']\n",
        "\n",
        "# Create a correlation matrix\n",
        "correlation_matrix = filtered_data[columns].corr()\n",
        "\n",
        "# Generate the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix of Non-Categorical Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create subset dataframe by removing related offer and promotion features\n",
        "subset_df = filtered_data.drop(['AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Response'], axis=1)\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(subset_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subset_df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform dimensionality reduction using PCA with 3 components\n",
        "pca = PCA(n_components=3)\n",
        "reduced_data = pca.fit_transform(scaled_data)\n",
        "\n",
        "# Create a new dataframe with the reduced data\n",
        "reduced_df = pd.DataFrame(reduced_data, columns=['PC1', 'PC2', 'PC3'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reduced_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Langkah k"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Perform K-Means clustering with different values of k\n",
        "wcss = []\n",
        "k_values = range(1, 10)\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(reduced_df)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow curve to find the optimal number of clusters\n",
        "plt.plot(k_values, wcss, 'bx-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Curve')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_kmeans = kmeans.fit_predict(reduced_df)\n",
        "# Visualize the clustering result using a scatter plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(reduced_df['PC1'], reduced_df['PC2'], reduced_df['PC3'], c=y_kmeans)\n",
        "ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "           kmeans.cluster_centers_[:, 2], s=300, c='yellow', label='Centroids')\n",
        "ax.set_xlabel('PC1')\n",
        "ax.set_ylabel('PC2')\n",
        "ax.set_zlabel('PC3')\n",
        "ax.set_title('K-means Clustering')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Install plotly library if not installed\n",
        "# %pip install plotly\n",
        "# import plotly.express as px\n",
        "\n",
        "# # Create a dataframe for the scatter plot\n",
        "# scatter_df = reduced_df.copy()\n",
        "# scatter_df['Cluster'] = y_kmeans\n",
        "\n",
        "# # Create the interactive 3D scatter plot\n",
        "# fig = px.scatter_3d(scatter_df, x='PC1', y='PC2', z='PC3', color='Cluster',\n",
        "#                     symbol='Cluster', opacity=0.8)\n",
        "\n",
        "# # Add centroids to the plot\n",
        "# centroid_df = pd.DataFrame(kmeans.cluster_centers_, columns=['PC1', 'PC2', 'PC3'])\n",
        "# centroid_df['Cluster'] = range(kmeans.n_clusters)\n",
        "# fig.add_trace(px.scatter_3d(centroid_df, x='PC1', y='PC2', z='PC3', color='Cluster',\n",
        "#                             symbol='Cluster', size_max=10).data[0])\n",
        "\n",
        "# # Update layout and axis labels\n",
        "# fig.update_layout(title='K-means Clustering',\n",
        "#                   scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'))\n",
        "\n",
        "# # Show the interactive plot\n",
        "# fig.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Perform Agglomerative clustering and plot the dendrogram\n",
        "linkage_matrix = linkage(reduced_df, method='ward')\n",
        "dendrogram(linkage_matrix)\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "\n",
        "# Determine the number of clusters for different height thresholds\n",
        "heights = [0.1, 5, 10, 25, 50, 80]\n",
        "for height in heights:\n",
        "    num_clusters = len(set(linkage_matrix[:, 2][linkage_matrix[:, 2] > height])) + 1\n",
        "    plt.axhline(y=height, color='r', linestyle='--')\n",
        "    plt.text(linkage_matrix[-1, 2], height, f'Clusters: {num_clusters}', ha='left', va='center')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Perform DBSCAN clustering with different values of epsilon and min_samples\n",
        "eps_values = [0.3, 0.5, 0.7]\n",
        "min_samples_values = [2, 5, 7, 9, 10, 15]\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        dbscan.fit(reduced_df)\n",
        "        labels = dbscan.labels_\n",
        "        num_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # Subtract 1 for noise points\n",
        "        \n",
        "        # Plot the clusters\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.scatter(reduced_df['PC1'], reduced_df['PC2'], reduced_df['PC3'], c=labels)\n",
        "        ax.set_xlabel('PC1')\n",
        "        ax.set_ylabel('PC2')\n",
        "        ax.set_zlabel('PC3')\n",
        "        ax.set_title(f'DBSCAN Clustering (epsilon={eps}, min_samples={min_samples})')\n",
        "        ax.text2D(0.95, 0.05, f'Clusters: {num_clusters}', ha='right', va='center', transform=ax.transAxes)\n",
        "        plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3D visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Perform DBSCAN clustering with different values of epsilon and min_samples\n",
        "eps_values = [0.3, 0.5, 0.7]\n",
        "min_samples_values = [2, 5, 7, 9, 10, 15]\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        dbscan.fit(reduced_df)\n",
        "        labels = dbscan.labels_\n",
        "        num_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # Subtract 1 for noise points\n",
        "        \n",
        "        # Create the interactive 3D scatter plot\n",
        "        fig = go.Figure(data=go.Scatter3d(\n",
        "            x=reduced_df['PC1'],\n",
        "            y=reduced_df['PC2'],\n",
        "            z=reduced_df['PC3'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=3,\n",
        "                color=labels,\n",
        "                colorscale='Viridis',\n",
        "                opacity=0.8\n",
        "            )\n",
        "        ))\n",
        "\n",
        "        # Update layout and axis labels\n",
        "        fig.update_layout(\n",
        "            title=f'DBSCAN Clustering (epsilon={eps}, min_samples={min_samples})',\n",
        "            scene=dict(\n",
        "                xaxis_title='PC1',\n",
        "                yaxis_title='PC2',\n",
        "                zaxis_title='PC3'\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        # Add text annotation for the number of clusters\n",
        "        fig.add_annotation(\n",
        "            x=0.95,\n",
        "            y=0.05,\n",
        "            text=f'Clusters: {num_clusters}',\n",
        "            showarrow=False,\n",
        "            font=dict(color='black')\n",
        "        )\n",
        "        \n",
        "        # Set the aspect ratio of the 3D plot\n",
        "        fig.update_layout(scene=dict(aspectmode='data'))\n",
        "        \n",
        "        # Show the interactive plot\n",
        "        pio.show(fig)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
